"""
ç‰©æ–™æµè½¬åŒå‘å®¡è®¡æŠ¥å‘Šç”Ÿæˆå™¨

è¾“å…¥ï¼ˆdata/raw/ï¼‰ï¼š
  shop_orders_latest.json       â€” IMES å·¥å•æ•°æ®
  bom_details_latest.json       â€” IMES BOM æ˜ç»†
  inventory_latest.csv          â€” SSRS çº¿è¾¹ä»“åº“å­˜
  nwms_issue_details_latest.json â€” NWMS å‘æ–™è¡Œæ˜ç»†ï¼ˆå¯é€‰ï¼Œæœªè¿è¡Œæ—¶é€€åŒ–ä¸ºä¸‰è¡¨åˆ†æï¼‰

è¾“å‡ºï¼ˆdata/raw/ï¼‰ï¼š
  alert_report.csv              â€” é€€æ–™é¢„è­¦ï¼ˆç¦»åœºå®¡è®¡ï¼‰ï¼šå®Œå·¥å·¥å•ä»æœ‰çº¿è¾¹ä»“åº“å­˜
  issue_audit_report.csv        â€” è¶…å‘é¢„è­¦ï¼ˆè¿›åœºå®¡è®¡ï¼‰ï¼šå®é™…å‘æ–™ > BOMè®¡åˆ’ï¼ˆéœ€NWMSæ•°æ®ï¼‰

è¿è¡Œï¼š
  python3 src/analysis/build_report.py
"""

import json
import csv
import io
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from src.config.common_materials import COMMON_MATERIALS

BASE = Path(__file__).parent.parent.parent / "data" / "raw"

COMPLETED_STATUSES = {"Completado", "å®Œæˆ", "Completed", "å·²å®Œæˆ", "Se ha iniciado la construcciÃ³n"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•°æ®åŠ è½½
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_shop_orders():
    path = BASE / "shop_orders_latest.json"
    with open(path, encoding="utf-8") as f:
        orders = json.load(f)
    return {o["shopOrder"]: o for o in orders if o.get("shopOrder")}


def load_bom():
    path = BASE / "bom_details_latest.json"
    with open(path, encoding="utf-8") as f:
        rows = json.load(f)
    # ç´¢å¼•ï¼š(shopOrder, componentGbo) â†’ bomè¡Œ
    index = {}
    for r in rows:
        key = (r.get("shopOrder", ""), r.get("componentGbo", ""))
        if key[0] and key[1]:
            index[key] = r
    return index


def load_inventory():
    """
    è¿”å›ä¸¤ä¸ªç»“æ„ï¼š
    - grouped: (wo, mat) â†’ æ±‡æ€»æ•°æ®ï¼Œç”¨äºé€€æ–™é¢„è­¦åˆ†æ
    - raw_rows: åŸå§‹æ¡ç çº§è¡Œåˆ—è¡¨ï¼Œç”¨äºç”Ÿæˆ alert_report_detail.csv
    """
    path = BASE / "inventory_latest.csv"
    with open(path, encoding="utf-8-sig") as f:
        rows = list(csv.DictReader(f))

    raw_rows = []
    grouped = defaultdict(lambda: {
        "qty": 0.0, "barcodes": 0,
        "desc": "", "warehouse": "", "unit": "",
        "receive_time": "", "issue_time": "",
        "barcode_list": [],
    })
    for r in rows:
        wo = (r.get("æŒ‡å®šå·¥å•") or "").strip()
        mat = (r.get("ç‰©æ–™") or "").strip()
        qty_str = (r.get("ç°å­˜é‡") or "0").replace(",", "")
        try:
            qty = float(qty_str)
        except ValueError:
            qty = 0.0
        if not wo or not mat or qty <= 0.01:
            continue
        key = (wo, mat)
        g = grouped[key]
        g["qty"] += qty
        g["barcodes"] += 1
        barcode = r.get("æ¡ç ", "").strip() or r.get("barcode", "").strip()
        if barcode and barcode not in g["barcode_list"]:
            g["barcode_list"].append(barcode)
        g["desc"] = g["desc"] or r.get("ç‰©æ–™æè¿°", "")
        g["warehouse"] = g["warehouse"] or r.get("çº¿è¾¹ä»“æè¿°", r.get("çº¿è¾¹ä»“", ""))
        g["unit"] = g["unit"] or r.get("å•ä½", "")
        rt = r.get("æ¥æ”¶æ—¶é—´", "")
        if rt and (not g["receive_time"] or rt < g["receive_time"]):
            g["receive_time"] = rt
        it = r.get("æœ€æ–°å‘æ–™å•æ—¶é—´", "")
        if it and it > g["issue_time"]:
            g["issue_time"] = it
        # ä¿ç•™åŸå§‹æ¡ç è¡Œï¼ˆå«WO/ç‰©æ–™/æ¡ç /ç°å­˜é‡/æ—¶é—´ï¼‰
        raw_rows.append({
            "æŒ‡å®šå·¥å•": wo,
            "ç‰©æ–™ç¼–å·": mat,
            "ç‰©æ–™æè¿°": r.get("ç‰©æ–™æè¿°", ""),
            "æ¡ç ": r.get("æ¡ç ", ""),
            "ç°å­˜é‡": qty,
            "å•ä½": r.get("å•ä½", ""),
            "çº¿è¾¹ä»“": r.get("çº¿è¾¹ä»“æè¿°", r.get("çº¿è¾¹ä»“", "")),
            "æ¥æ”¶æ—¶é—´": r.get("æ¥æ”¶æ—¶é—´", ""),
            "æœ€æ–°å‘æ–™æ—¶é—´": r.get("æœ€æ–°å‘æ–™å•æ—¶é—´", ""),
        })

    return grouped, raw_rows


def load_nwms_lines():
    """åŠ è½½ NWMS å‘æ–™è¡Œæ˜ç»†ï¼Œå¯é€‰ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨æ—¶è¿”å›ç©ºï¼‰"""
    path = BASE / "nwms_issue_details_latest.json"
    if not path.exists():
        return None

    with open(path, encoding="utf-8") as f:
        rows = json.load(f)

    # æŒ‰ componentCode ç´¢å¼•ï¼ŒåŒæ—¶å¤„ç† _workOrderNum å¯èƒ½å«å¤šä¸ªå·¥å•ï¼ˆé€—å·åˆ†éš”ï¼‰
    # è¿”å›ç»“æ„ï¼š{componentCode: [{instructionDocId, workOrderNums:set, demandQty, actualQty, status, ...}]}
    by_component = defaultdict(list)
    for r in rows:
        comp = (r.get("componentCode") or "").strip()
        if not comp:
            continue
        wo_raw = (r.get("_workOrderNum") or "").strip()
        wos = set(w.strip() for w in wo_raw.split(",") if w.strip())
        related = (r.get("relatedWoLine") or "").strip()
        related_wos = set(w.strip() for w in related.split(",") if w.strip())
        wos |= related_wos

        try:
            demand = float(r.get("demandQuantity") or 0)
        except (ValueError, TypeError):
            demand = 0.0
        try:
            actual = float(r.get("actualQuantity") or 0)
        except (ValueError, TypeError):
            actual = 0.0

        by_component[comp].append({
            "docId": r.get("_instructionDocId", ""),
            "docNum": r.get("_demandListNumber", ""),
            "workOrders": wos,
            "demandQty": demand,
            "actualQty": actual,
            "status": r.get("status", ""),
            "productionLine": r.get("_productionLine", ""),
            "warehouse": r.get("_wareHouse", ""),
            "docStatus": r.get("_docStatus", ""),
            "ppStartTime": r.get("_ppStartTime", ""),
        })

    print(f"  NWMS å‘æ–™è¡Œ: {sum(len(v) for v in by_component.values())} æ¡ï¼Œ"
          f"æ¶‰åŠ {len(by_component)} ç§ç‰©æ–™")
    return by_component


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åˆ†æ 1ï¼šé€€æ–™é¢„è­¦ï¼ˆç¦»åœºå®¡è®¡ï¼‰
# æ¡ä»¶ï¼šå·¥å•å·²å®Œæˆ AND è¯¥å·¥å•+ç‰©æ–™ä»æœ‰çº¿è¾¹ä»“åº“å­˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_return_alert(orders, bom_index, inventory):
    """ç”Ÿæˆé€€æ–™é¢„è­¦æŠ¥å‘Š"""
    results = []

    for (wo, mat), inv in inventory.items():
        order = orders.get(wo)
        if not order:
            continue
        if order.get("statusDesc") not in COMPLETED_STATUSES:
            continue

        bom = bom_index.get((wo, mat))
        qty_done = float(order.get("qtyDone") or 0)
        qty_ordered = float(order.get("qtyOrdered") or 0)

        if bom:
            unit_qty = float(bom.get("qty") or 0)
            sum_qty = float(bom.get("sumQty") or 0)
            send_qty = float(bom.get("sendQty") or 0)
            theoretical_remainder = sum_qty - qty_done * unit_qty
        else:
            unit_qty = sum_qty = send_qty = theoretical_remainder = None

        actual_inv = inv["qty"]
        deviation = (actual_inv - theoretical_remainder) if theoretical_remainder is not None else None

        results.append({
            "å·¥å•å·": wo,
            "ç‰©æ–™ç¼–å·": mat,
            "ç‰©æ–™æè¿°": inv["desc"],
            "çº¿è¾¹ä»“": inv["warehouse"],
            "å•ä½": inv["unit"],
            "å®é™…åº“å­˜(åˆè®¡)": round(actual_inv, 2),
            "æ¡ç æ•°": inv["barcodes"],
            "barcode_list": inv.get("barcode_list", []),
            "å·¥å•çŠ¶æ€": order.get("statusDesc", ""),
            "è®¡åˆ’æ•°é‡": qty_ordered,
            "å®Œå·¥æ•°é‡": qty_done,
            "BOMå•ä»¶ç”¨é‡": unit_qty,
            "BOMæ€»éœ€æ±‚é‡": sum_qty,
            "å·²å‘æ–™é‡(sendQty)": send_qty,
            "ç†è®ºä½™æ–™": round(theoretical_remainder, 2) if theoretical_remainder is not None else "",
            "åå·®(å®é™…-ç†è®º)": round(deviation, 2) if deviation is not None else "",
            "æ¥æ”¶æ—¶é—´": inv["receive_time"],
            "æœ€æ–°å‘æ–™æ—¶é—´": inv["issue_time"],
            "is_legacy": _is_legacy(inv["receive_time"]),
            "aging_days": round((datetime.now() - _parse_date(inv["receive_time"])).total_seconds() / 86400, 1) if _parse_date(inv["receive_time"]) else -1.0,
        })

    results.sort(key=lambda x: (
        -(x["åå·®(å®é™…-ç†è®º)"] if isinstance(x["åå·®(å®é™…-ç†è®º)"], float) else 0),
        x["å·¥å•å·"],
    ))
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åˆ†æ 2ï¼šè¶…å‘é¢„è­¦ï¼ˆè¿›åœºå®¡è®¡ï¼‰
# æ•°æ®æ¥æºï¼šNWMS woissueLineDetail çš„ actualQuantity vs demandQuantity
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_issue_audit(nwms_by_component, orders, bom_index):
    """ç”Ÿæˆè¶…å‘é¢„è­¦æŠ¥å‘Šï¼ˆéœ€è¦ NWMS æ•°æ®ï¼‰"""
    results = []
    nwms_total = sum(len(v) for v in nwms_by_component.values())
    nwms_matched = 0
    seen = set()

    # ä»¥ NWMS å‘æ–™è¡Œä¸ºä¸»è¡¨
    for comp, lines in nwms_by_component.items():
        for ln in lines:
            doc_id = ln["docId"]
            key = (doc_id, comp)
            if key in seen:
                continue
            seen.add(key)

            # â”€â”€ åˆ†æå±‚è¿‡æ»¤ï¼šå…³è”å·¥å•å¿…é¡»å­˜åœ¨äº IMES å·¥å•é›†åˆ â”€â”€
            has_matched_wo = any(wo in orders for wo in ln["workOrders"])
            if not has_matched_wo:
                continue  # ä¸¢å¼ƒï¼Œè®¡å…¥æœªåŒ¹é…ç»Ÿè®¡
            nwms_matched += 1

            demand = ln["demandQty"]
            actual = ln["actualQty"]
            over_issue = actual - demand
            over_rate = (over_issue / demand * 100) if demand > 0 else 0

            # å°è¯•å…³è” IMES å·¥å•ï¼ˆå–ç¬¬ä¸€ä¸ªåŒ¹é…çš„å·¥å•ï¼‰
            matched_wo = ""
            matched_order = None
            matched_bom = None
            for wo in ln["workOrders"]:
                if wo in orders:
                    matched_wo = wo
                    matched_order = orders[wo]
                    matched_bom = bom_index.get((wo, comp))
                    break

            # BOM æ ‡å‡†éœ€æ±‚é‡åŠå…¶è¶…å‘è®¡ç®—
            bom_sum_qty = float(matched_bom.get("sumQty") or 0) if matched_bom else 0.0
            over_vs_bom = round(actual - bom_sum_qty, 2) if bom_sum_qty > 0 else ""
            over_vs_bom_rate = round((actual - bom_sum_qty) / bom_sum_qty * 100, 1) if bom_sum_qty > 0 else ""
            if over_vs_bom == "":
                over_vs_bom_label = "(BOMæ— æ•°æ®)"
            elif isinstance(over_vs_bom, float) and over_vs_bom > 0.01:
                over_vs_bom_label = "âš ï¸ è¶…å‘(BOM)"
            elif isinstance(over_vs_bom, float) and over_vs_bom >= -0.01:
                over_vs_bom_label = "âœ… æ­£å¸¸(BOM)"
            else:
                over_vs_bom_label = "ğŸ”½ å°‘å‘(BOM)"

            results.append({
                "å¤‡æ–™å•ID": doc_id,
                "å¤‡æ–™å•å·": ln["docNum"],
                "å¤‡æ–™å•çŠ¶æ€": ln["docStatus"],
                "å…³è”å·¥å•": ",".join(sorted(ln["workOrders"])),
                "ç‰©æ–™ç¼–å·": comp,
                # NWMS å£å¾„
                "è®¡åˆ’å‘æ–™é‡(demandQty)": round(demand, 2),
                "å®é™…å‘æ–™é‡(actualQty)": round(actual, 2),
                "è¶…å‘é‡": round(over_issue, 2),
                "è¶…å‘ç‡(%)": round(over_rate, 1),
                "æ˜¯å¦è¶…å‘": "âš ï¸ è¶…å‘" if over_issue > 0.01 else ("âœ… æ­£å¸¸" if over_issue >= -0.01 else "ğŸ”½ å°‘å‘"),
                # BOM å£å¾„
                "BOMæ ‡å‡†éœ€æ±‚é‡(sumQty)": bom_sum_qty if bom_sum_qty > 0 else "",
                "è¶…å‘é‡(vs BOM)": over_vs_bom,
                "è¶…å‘ç‡%(vs BOM)": over_vs_bom_rate,
                "æ˜¯å¦è¶…å‘(BOMå£å¾„)": over_vs_bom_label,
                # å…¶ä»–ä¿¡æ¯
                "å‘æ–™çŠ¶æ€": ln["status"],
                "äº§çº¿": ln["productionLine"],
                "ä»“åº“": ln["warehouse"],
                "IMESå·¥å•çŠ¶æ€": matched_order.get("statusDesc", "") if matched_order else "",
                "è®¡åˆ’å‘æ–™æ—¥æœŸ": ln.get("ppStartTime", ""),
            })

    # æŒ‰è¶…å‘é‡é™åºæ’åˆ—ï¼ˆæœ€ä¸¥é‡çš„æ’å‰é¢ï¼‰
    results.sort(key=lambda x: -(x["è¶…å‘é‡"] if isinstance(x["è¶…å‘é‡"], float) else 0))
    return results, nwms_total, nwms_matched


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¿å­˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def save_csv(rows, filename):
    if not rows:
        print(f"  [SKIP] {filename} â€” æ— æ•°æ®")
        return
    path = BASE / filename
    with open(path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()), extrasaction="ignore")
        writer.writeheader()
        writer.writerows(rows)
    print(f"  [SAVE] {path}  ({len(rows)} è¡Œ)")


def safe_float(val):
    try:
        if val == "":
            return 0.0
        return float(val)
    except (ValueError, TypeError):
        return 0.0

def safe_str(val):
    if val is None:
        return ""
    return str(val)

def _parse_date(date_str: str):
    """å°è¯•ä»å­—ç¬¦ä¸²è§£ææ—¥æœŸï¼Œå¤±è´¥è¿”å› None
    å…¼å®¹æ ¼å¼ï¼š
      '2026-02-18 14:54:53'  (è¿å­—ç¬¦ï¼Œæ ‡å‡†)
      '2026/2/18 14:54:53'   (æ–œæ ï¼ŒSSRS åº“å­˜ CSV å®é™…æ ¼å¼)
      '2026/2/6 9:57:22'     (æ–œæ  + å•ä½æ•°æœˆ/æ—¥/æ—¶)
    """
    if not date_str:
        return None
    try:
        s = str(date_str).strip()
        # å…ˆå–ç©ºæ ¼å‰çš„æ—¥æœŸéƒ¨åˆ†ï¼ˆé¿å… [:10] æˆªå…¥æ—¶é—´ï¼‰
        date_part = s.split(" ")[0].replace("/", "-")
        # è¡¥é½å•ä½æ•°æœˆ/æ—¥ï¼š2026-2-6 â†’ 2026-02-06
        parts = date_part.split("-")
        if len(parts) == 3:
            date_part = f"{parts[0]}-{int(parts[1]):02d}-{int(parts[2]):02d}"
        return datetime.strptime(date_part, "%Y-%m-%d")
    except (ValueError, TypeError, IndexError):
        return None

def _is_legacy(receive_time_str: str) -> bool:
    d = _parse_date(receive_time_str)
    return d is None or d < datetime(2026, 1, 1)





# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸»æµç¨‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run():
    print("=" * 60)
    print("ç‰©æ–™æµè½¬åŒå‘å®¡è®¡æŠ¥å‘Šç”Ÿæˆå™¨")
    print(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # åŠ è½½æ•°æ®
    print("\n[1/4] åŠ è½½ IMES å·¥å•æ•°æ®...")
    orders = load_shop_orders()
    print(f"  å·¥å•: {len(orders)} æ¡")

    print("[2/4] åŠ è½½ IMES BOM æ•°æ®...")
    bom_index = load_bom()
    print(f"  BOMè¡Œ: {len(bom_index)} æ¡")

    print("[3/4] åŠ è½½ SSRS çº¿è¾¹ä»“åº“å­˜...")
    inventory, inventory_raw = load_inventory()
    print(f"  æœ‰æ•ˆåº“å­˜ç»„åˆ(å·¥å•+ç‰©æ–™): {len(inventory)} ç»„ï¼Œæ¡ç è¡Œ: {len(inventory_raw)} æ¡")

    print("[4/4] åŠ è½½ NWMS å‘æ–™è¡Œæ˜ç»†ï¼ˆå¯é€‰ï¼‰...")
    nwms_lines = load_nwms_lines()
    if nwms_lines is None:
        print("  [è·³è¿‡] nwms_issue_details_latest.json ä¸å­˜åœ¨ï¼Œè·³è¿‡è¿›åœºå®¡è®¡")
        print("  è¿è¡Œ 'python3 src/scrapers/nwms_scraper.py' è·å– NWMS æ•°æ®")

    # åˆ†æ 1ï¼šé€€æ–™é¢„è­¦
    print("\nâ”€â”€â”€ é€€æ–™é¢„è­¦ï¼ˆç¦»åœºå®¡è®¡ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    alert = build_return_alert(orders, bom_index, inventory)

    print(f"  å®Œå·¥å·¥å•ä»æœ‰åº“å­˜çš„ç»„åˆ: {len(alert)} ç»„")
    over_positive = [r for r in alert if isinstance(r["åå·®(å®é™…-ç†è®º)"], float) and r["åå·®(å®é™…-ç†è®º)"] > 0.01]
    print(f"  å…¶ä¸­åå·® > 0ï¼ˆè´¦é¢è¶…å‘/å¤šä½™ï¼‰: {len(over_positive)} ç»„")
    save_csv(alert, "alert_report.csv")

    # é€€æ–™é¢„è­¦æ˜ç»†ï¼ˆæ¡ç çº§ï¼Œä¾› Page 2 æ“ä½œæ˜ç»†ä½¿ç”¨ï¼‰
    alert_wo_mat = {(r["å·¥å•å·"], r["ç‰©æ–™ç¼–å·"]): r for r in alert}
    detail_rows = []
    for row in inventory_raw:
        key = (row["æŒ‡å®šå·¥å•"], row["ç‰©æ–™ç¼–å·"])
        if key not in alert_wo_mat:
            continue
        a = alert_wo_mat[key]
        detail_rows.append({
            **row,
            "å·¥å•çŠ¶æ€": a.get("å·¥å•çŠ¶æ€", ""),
            "å®Œå·¥æ•°é‡": a.get("å®Œå·¥æ•°é‡", ""),
            "åå·®(æ‰€å±ç»„)": a.get("åå·®(å®é™…-ç†è®º)", ""),
            "ç†è®ºä½™æ–™": a.get("ç†è®ºä½™æ–™", ""),
        })
    detail_rows.sort(key=lambda x: (x["æŒ‡å®šå·¥å•"], x["ç‰©æ–™ç¼–å·"]))
    save_csv(detail_rows, "alert_report_detail.csv")
    print(f"  æ¡ç æ˜ç»†è¡Œæ•°: {len(detail_rows)}")

    # åˆ†æ 2ï¼šè¶…å‘é¢„è­¦ï¼ˆNWMS æ•°æ®å¯ç”¨æ—¶ï¼‰
    if nwms_lines:
        print("\nâ”€â”€â”€ è¶…å‘é¢„è­¦ï¼ˆè¿›åœºå®¡è®¡ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        issue_audit, nwms_total, nwms_matched = build_issue_audit(nwms_lines, orders, bom_index)
        over_issued = [r for r in issue_audit if r["è¶…å‘é‡"] > 0.01]
        print(f"  å‘æ–™è¡Œæ€»è®¡: {len(issue_audit)} æ¡")
        print(f"  å…¶ä¸­è¶…å‘: {len(over_issued)} æ¡")
        if issue_audit:
            top5 = over_issued[:5]
            for r in top5:
                print(f"  âš ï¸  {r['ç‰©æ–™ç¼–å·']} | è®¡åˆ’={r['è®¡åˆ’å‘æ–™é‡(demandQty)']} å®å‘={r['å®é™…å‘æ–™é‡(actualQty)']} "
                      f"è¶…å‘={r['è¶…å‘é‡']} | å¤‡æ–™å•={r['å¤‡æ–™å•å·']}")
        save_csv(issue_audit, "issue_audit_report.csv")
    else:
        issue_audit = []

    # æ±‡æ€»
    print("\nâ”€â”€â”€ æ±‡æ€» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  é€€æ–™é¢„è­¦ç»„æ•°: {len(alert)}")
    print(f"  åå·®>0 (éœ€ç«‹å³å¤„ç†): {len(over_positive)}")
    if nwms_lines:
        print(f"  è¶…å‘å‘æ–™è¡Œ: {len(over_issued)}")
    print("\n[å®Œæˆ] æŠ¥å‘Šå·²ä¿å­˜åˆ° data/raw/")
    
    # â”€â”€ åº“é¾„ä¸åˆ†ç±»ç»Ÿè®¡ (Phase 3) â”€â”€
    NOW = datetime.now()
    def _aging_days(receive_time_str: str) -> float:
        d = _parse_date(receive_time_str)
        if d is None:
            return -1.0
        return (NOW - d).total_seconds() / 86400

    confirmed_alerts = [
        r for r in alert
        if not r.get("is_legacy")
        and r.get("å·¥å•å·") in orders
    ]
    confirmed_alerts_excl = [
        r for r in confirmed_alerts
        if r.get("ç‰©æ–™ç¼–å·", "") not in COMMON_MATERIALS
    ]
    unmatched_current = [
        (wo, mat) for (wo, mat), inv in inventory.items()
        if not _is_legacy(inv["receive_time"])
        and wo not in orders
    ]
    legacy_items = [
        (wo, mat) for (wo, mat), inv in inventory.items()
        if _is_legacy(inv["receive_time"])
    ]

    aging_dist = {"le1": 0, "d1_3": 0, "d3_7": 0, "d7_14": 0, "d14_30": 0, "gt30": 0}
    aging_hours_list = []
    aging_hours_list_excl = []

    for r in confirmed_alerts:
        days = _aging_days(r.get("æ¥æ”¶æ—¶é—´", ""))
        if days < 0:
            continue
        
        hours = days * 24
        aging_hours_list.append(hours)
        if r.get("ç‰©æ–™ç¼–å·", "") not in COMMON_MATERIALS:
            aging_hours_list_excl.append(hours)
        if days <= 1:
            aging_dist["le1"] += 1
        elif days <= 3:
            aging_dist["d1_3"] += 1
        elif days <= 7:
            aging_dist["d3_7"] += 1
        elif days <= 14:
            aging_dist["d7_14"] += 1
        elif days <= 30:
            aging_dist["d14_30"] += 1
        else:
            aging_dist["gt30"] += 1

    avg_aging_current = round(sum(aging_hours_list) / len(aging_hours_list), 1) if aging_hours_list else 0.0
    avg_aging_current_excl = round(sum(aging_hours_list_excl) / len(aging_hours_list_excl), 1) if aging_hours_list_excl else 0.0

    # â”€â”€ æ•°æ®è´¨é‡ç»Ÿè®¡ â”€â”€
    legacy_rows = [r for r in inventory_raw if _is_legacy(r.get("æ¥æ”¶æ—¶é—´", ""))]
    alert_current = [r for r in alert if not r.get("is_legacy")]
    alert_matched = len(alert_current)
    alert_unmatched = len([
        (wo, mat) for (wo, mat), inv in inventory.items()
        if not _is_legacy(inv["receive_time"])
        and (wo, mat) not in {(r["å·¥å•å·"], r["ç‰©æ–™ç¼–å·"]) for r in alert_current}
        and wo not in orders  # æœ‰åº“å­˜ä½†å·¥å•ä¸å­˜åœ¨
    ])
    alert_match_rate = round(
        alert_matched / (alert_matched + alert_unmatched) * 100, 1
    ) if (alert_matched + alert_unmatched) > 0 else 0.0

    quality_stats = {
        "inventory_total": len(inventory_raw),
        "inventory_legacy": len(legacy_rows),
        "inventory_current": len(inventory_raw) - len(legacy_rows),
        "orders_total": len(orders),
        "alert_matched": alert_matched,
        "alert_unmatched": alert_unmatched,
        "alert_match_rate": alert_match_rate,
        "nwms_lines_total": nwms_total if nwms_lines else 0,
        "nwms_lines_matched": nwms_matched if nwms_lines else 0,
        "nwms_match_rate": round(nwms_matched / nwms_total * 100, 1) if nwms_lines and nwms_total > 0 else 0.0,
        "confirmed_alert_count": len(confirmed_alerts),
        "confirmed_alert_count_excl": len(confirmed_alerts_excl),
        "unmatched_current_count": len(unmatched_current),
        "legacy_count": len(legacy_items),
        "avg_aging_hours_current": avg_aging_current,
        "avg_aging_hours_excl": avg_aging_current_excl,
        "aging_distribution": aging_dist,
    }
    
    return alert, issue_audit, quality_stats

if __name__ == "__main__":
    run()

